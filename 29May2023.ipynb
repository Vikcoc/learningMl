{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a90e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"29Mai2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b171e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Instrument', axis=1, inplace=True)\n",
    "df.drop('OpenInterest', axis=1, inplace=True)\n",
    "df.drop('TradeTimestamp', axis=1, inplace=True)\n",
    "df.drop('Timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "521d253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
      "/tmp/ipykernel_19576/1766425678.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
      "/tmp/ipykernel_19576/1766425678.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
      "/tmp/ipykernel_19576/1766425678.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
      "/tmp/ipykernel_19576/1766425678.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
      "/tmp/ipykernel_19576/1766425678.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
      "/tmp/ipykernel_19576/1766425678.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    #df[f'High{i+1}'] = df['High'].shift(i+1) - df['High']\n",
    "    #df[f'Low{i+1}'] = df['Low'].shift(i+1) - df['Low']\n",
    "    df[f'Actual{i+1}'] = df['Actual'].shift(i+1) -  df['Actual']\n",
    "    df[f'Volume{i+1}'] = df['Volume'].shift(i+1) - df['Volume']\n",
    "    #df[f'UsdVolume{i+1}'] = df['UsdVolume'].shift(i+1) - df['UsdVolume']\n",
    "    df[f'Change{i+1}'] = df['Change'].shift(i+1) - df['Change']\n",
    "    df[f'BestBid{i+1}'] = df['BestBid'].shift(i+1) - df['BestBid']\n",
    "    df[f'BestBidSize{i+1}'] = df['BestBidSize'].shift(i+1) - df['BestBidSize']\n",
    "    df[f'BestAsk{i+1}'] = df['BestAsk'].shift(i+1) - df['BestAsk']\n",
    "    df[f'BestAskSize{i+1}'] = df['BestAskSize'].shift(i+1) - df['BestAskSize']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a734a778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19576/3151075095.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ActualF50'] = df['Actual'].shift(-50) -  df['Actual']\n"
     ]
    }
   ],
   "source": [
    "df[f'ActualF50'] = df['Actual'].shift(-50) -  df['Actual']\n",
    "df['ActualF50'] = df['ActualF50'].apply(lambda x: 1 if x >= 1 else -1 if x <= -1 else 0)\n",
    "df.drop('High', axis=1, inplace=True)\n",
    "df.drop('Low', axis=1, inplace=True)\n",
    "df.drop('Actual', axis=1, inplace=True)\n",
    "df.drop('Volume', axis=1, inplace=True)\n",
    "df.drop('UsdVolume', axis=1, inplace=True)\n",
    "df.drop('Change', axis=1, inplace=True)\n",
    "df.drop('BestBid', axis=1, inplace=True)\n",
    "df.drop('BestBidSize', axis=1, inplace=True)\n",
    "df.drop('BestAsk', axis=1, inplace=True)\n",
    "df.drop('BestAskSize', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2001940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[50:4879]\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6076e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Actual1  Volume1  Change1  BestBid1  BestBidSize1  BestAsk1   \n",
      "50       0.47  -1.0786   0.0003      0.22       -2.0701      0.04  \\\n",
      "51      -0.26  -0.0600  -0.0002      0.19        1.9000     -0.04   \n",
      "52       0.05  -0.0600   0.0000     -0.01        0.1998      0.39   \n",
      "53       0.23  -0.0100   0.0002      0.11       -0.1997      0.00   \n",
      "54      -0.14  -0.0155  -0.0001      0.03        0.0000      0.00   \n",
      "...       ...      ...      ...       ...           ...       ...   \n",
      "4874     0.24  -0.0400   0.0001      0.26       -7.4921      0.28   \n",
      "4875     0.30  -0.3600   0.0002      0.22        7.3410      0.09   \n",
      "4876    -0.01   0.0710   0.0002      0.00        0.0000      0.17   \n",
      "4877     0.22  -0.0167   0.0001      0.00        0.0067      0.10   \n",
      "4878     0.70  -2.8265   0.0004      0.62       -4.3477      0.64   \n",
      "\n",
      "      BestAskSize1  Actual2  Volume2  Change2  ...  BestAsk49  BestAskSize49   \n",
      "50          0.0000     0.48  -1.1386   0.0003  ...      -0.04         0.0000  \\\n",
      "51          0.0000     0.21  -1.1386   0.0001  ...      -0.01        -0.0002   \n",
      "52          0.0000    -0.21  -0.1200  -0.0002  ...       0.38        -0.0002   \n",
      "53          0.0000     0.28  -0.0700   0.0002  ...       0.36         0.2775   \n",
      "54          0.0000     0.09  -0.0255   0.0001  ...       0.17         0.2776   \n",
      "...            ...      ...      ...      ...  ...        ...            ...   \n",
      "4874        0.1419    -0.14  -0.0492  -0.0001  ...      -1.73         0.2433   \n",
      "4875        0.0000     0.54  -0.4000   0.0003  ...      -1.53        -0.0053   \n",
      "4876        0.0000     0.29  -0.2890   0.0004  ...      -1.37        -0.0078   \n",
      "4877       -0.2776     0.21   0.0543   0.0003  ...      -1.68         1.8368   \n",
      "4878        0.2776     0.92  -2.8432   0.0005  ...      -0.56         0.2421   \n",
      "\n",
      "      Actual50  Volume50  Change50  BestBid50  BestBidSize50  BestAsk50   \n",
      "50        0.38  -21.1076   -0.0001       0.03        -2.0998      -0.04  \\\n",
      "51        0.42  -21.1675   -0.0001       0.22        -0.1998      -0.08   \n",
      "52        0.32  -21.3889   -0.0003       0.21         0.0000       0.38   \n",
      "53        0.54  -21.3988   -0.0001       0.33         0.0624       0.38   \n",
      "54        0.18  -21.4043   -0.0003       0.37        -0.1999       0.36   \n",
      "...        ...       ...       ...        ...            ...        ...   \n",
      "4874     -1.88  -33.3278   -0.0012      -1.91        -7.4922      -1.84   \n",
      "4875     -1.47  -33.6614   -0.0009      -1.57         0.0510      -1.64   \n",
      "4876     -1.78  -33.5843   -0.0009      -1.56        -0.1511      -1.36   \n",
      "4877     -1.14  -33.5957   -0.0006      -1.59        -0.1445      -1.27   \n",
      "4878     -0.87  -36.4117   -0.0004      -0.99        -4.4921      -1.04   \n",
      "\n",
      "      BestAskSize50  ActualF50  \n",
      "50           0.0000         -1  \n",
      "51           0.0000         -1  \n",
      "52          -0.0002         -1  \n",
      "53          -0.0002         -1  \n",
      "54           0.2775         -1  \n",
      "...             ...        ...  \n",
      "4874         0.2697          0  \n",
      "4875         0.2433          0  \n",
      "4876        -0.0053          0  \n",
      "4877        -0.2854          0  \n",
      "4878         2.1144          0  \n",
      "\n",
      "[4829 rows x 351 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9c15a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0786 -0.06   -0.06   ... -0.1603  0.071  -2.8265]\n",
      "[-1.1386 -1.1386 -0.12   ... -0.289   0.0543 -2.8432]\n",
      "[-1.1986 -0.13   -0.0855 ... -0.329  -0.3057 -2.7722]\n",
      "[-1.2248 -1.2586 -1.2586 ... -0.3382 -0.3457 -3.1322]\n",
      "[-1.2348 -1.2848 -1.3186 ... -0.4985 -0.3549 -3.1722]\n",
      "[-1.2548 -1.2948 -1.3448 ... -0.5618 -0.5152 -3.1814]\n",
      "[-1.2702 -1.3148 -1.3548 ... -0.6729 -0.5785 -3.3417]\n",
      "[-1.4282 -1.3302 -1.3748 ... -0.6882 -0.6896 -3.405 ]\n",
      "[-1.4455 -1.4882 -1.3902 ... -1.3404 -0.7049 -3.5161]\n",
      "[ -1.7055  -1.5055  -1.5482 ... -28.7414  -1.3571  -3.5314]\n",
      "[ -2.6733  -1.7655  -1.5655 ... -28.7605 -28.7581  -4.1836]\n",
      "[ -1.7907  -2.7333  -1.8255 ... -28.7968 -28.7772 -31.5846]\n",
      "[ -1.803   -1.8507  -2.7933 ... -28.8175 -28.8135 -31.6037]\n",
      "[ -1.8166  -1.863   -1.9107 ... -28.8374 -28.8342 -31.64  ]\n",
      "[ -4.4542  -1.8766  -1.923  ... -28.8568 -28.8541 -31.6607]\n",
      "[ -4.4642  -4.5142  -1.9366 ... -28.8978 -28.8735 -31.6806]\n",
      "[ -5.0045  -4.5242  -4.5742 ... -28.9369 -28.9145 -31.7   ]\n",
      "[ -5.976   -5.0645  -4.5842 ... -28.5889 -28.9536 -31.741 ]\n",
      "[ -6.2714  -6.036   -5.1245 ... -28.6156 -28.6056 -31.7801]\n",
      "[ -3.5858  -6.3314  -6.096  ... -28.6354 -28.6323 -31.4321]\n",
      "[ -3.5958  -3.6458  -6.3914 ... -28.6555 -28.6521 -31.4588]\n",
      "[ -4.2333  -3.6558  -3.7058 ... -28.6748 -28.6722 -31.4786]\n",
      "[ -3.6716  -4.2933  -3.7158 ... -29.614  -28.6915 -31.4987]\n",
      "[ -3.6789  -3.7316  -4.3533 ... -29.6291 -29.6307 -31.518 ]\n",
      "[ -3.819   -3.7389  -3.7916 ... -29.6494 -29.6458 -32.4572]\n",
      "[ -3.8791  -3.879   -3.7989 ... -29.6692 -29.6661 -32.4723]\n",
      "[ -3.8792  -3.9391  -3.939  ... -29.6874 -29.6859 -32.4926]\n",
      "[ -3.8521  -3.9392  -3.9991 ... -29.7063 -29.7041 -32.5124]\n",
      "[ -3.8522  -3.9121  -3.9992 ... -29.7432 -29.723  -32.5306]\n",
      "[ -3.925   -3.9122  -3.9721 ... -29.7629 -29.7599 -32.5495]\n",
      "[ -3.9251  -3.985   -3.9722 ... -29.7801 -29.7796 -32.5864]\n",
      "[ -4.9231  -3.9851  -4.045  ... -29.7991 -29.7968 -32.6061]\n",
      "[ -4.9731  -4.9831  -4.0451 ... -29.8699 -29.8158 -32.6233]\n",
      "[ -4.5541  -5.0331  -5.0431 ... -29.8885 -29.8866 -32.6423]\n",
      "[ -4.5542  -4.6141  -5.0931 ... -29.908  -29.9052 -32.7131]\n",
      "[ -5.5542  -4.6142  -4.6741 ... -29.9263 -29.9247 -32.7317]\n",
      "[ -5.5651  -5.6142  -4.6742 ... -30.0465 -29.943  -32.7512]\n",
      "[ -4.6776  -5.6251  -5.6742 ... -31.8031 -30.0632 -32.7695]\n",
      "[ -4.6777  -4.7376  -5.6851 ... -32.0935 -31.8198 -32.8897]\n",
      "[ -4.678   -4.7377  -4.7976 ... -32.0936 -32.1102 -34.6463]\n",
      "[ -4.6877  -4.738   -4.7977 ... -32.1101 -32.1103 -34.9367]\n",
      "[ -3.9019  -4.7477  -4.798  ... -32.1263 -32.1268 -34.9368]\n",
      "[ -3.902   -3.9619  -4.8077 ... -32.1419 -32.143  -34.9533]\n",
      "[ -1.2218  -3.962   -4.0219 ... -32.577  -32.1586 -34.9695]\n",
      "[-21.2488  -1.2818  -4.022  ... -32.6046 -32.5937 -34.9851]\n",
      "[-21.2588 -21.3088  -1.3418 ... -32.6147 -32.6213 -35.4202]\n",
      "[-21.2688 -21.3188 -21.3688 ... -32.6347 -32.6314 -35.4478]\n",
      "[-21.2689 -21.3288 -21.3788 ... -33.5685 -32.6514 -35.4579]\n",
      "[-21.1075 -21.3289 -21.3888 ... -33.579  -33.5852 -35.4779]\n",
      "[-21.1076 -21.1675 -21.3889 ... -33.5843 -33.5957 -36.4117]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    print(df[f'Volume{i+1}'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188a3cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70      0\n",
      "71      0\n",
      "72      0\n",
      "73      0\n",
      "74      0\n",
      "       ..\n",
      "4874    0\n",
      "4875    0\n",
      "4876    0\n",
      "4877    0\n",
      "4878    0\n",
      "Name: ActualF50, Length: 1939, dtype: int64\n",
      "84      1\n",
      "85      1\n",
      "87      1\n",
      "89      1\n",
      "90      1\n",
      "       ..\n",
      "4830    1\n",
      "4831    1\n",
      "4834    1\n",
      "4835    1\n",
      "4836    1\n",
      "Name: ActualF50, Length: 1379, dtype: int64\n",
      "50     -1\n",
      "51     -1\n",
      "52     -1\n",
      "53     -1\n",
      "54     -1\n",
      "       ..\n",
      "4727   -1\n",
      "4728   -1\n",
      "4729   -1\n",
      "4730   -1\n",
      "4731   -1\n",
      "Name: ActualF50, Length: 1511, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "zeros = df[df['ActualF50'] == 0]\n",
    "ones  = df[df['ActualF50'] == 1]\n",
    "negatives = df[df['ActualF50'] == -1]\n",
    "print(zeros['ActualF50'])\n",
    "print(ones['ActualF50'])\n",
    "print(negatives['ActualF50'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a34da23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = zeros.sample(frac=1).reset_index(drop=True)\n",
    "zeros = zeros[:800]\n",
    "df = pd.concat([zeros, ones, negatives])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train_dataset = df.head(2000)\n",
    "test_dataset = df.tail(df.shape[0] - 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fe4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomPriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels, transform=None, target_transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = list(self.dataframe.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92903c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "trnlbl = train_dataset['ActualF50'] + 1\n",
    "trnset = train_dataset.drop('ActualF50', axis=1)\n",
    "trainPrice = CustomPriceDataset(trnset, trnlbl, torch.FloatTensor, Lambda(lambda y: torch.zeros(3, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
    "train_dataloader = DataLoader(trainPrice, batch_size=64)\n",
    "\n",
    "tstlbl = test_dataset['ActualF50'] + 1\n",
    "tstset = test_dataset.drop('ActualF50', axis=1)\n",
    "testPrice = CustomPriceDataset(tstset, tstlbl, torch.FloatTensor)\n",
    "test_dataloader = DataLoader(testPrice, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "919615bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(350, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98e0f723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8473b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "passed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905033f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=1e-2, dampening=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf2c39ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.128855  [   64/ 2000]\n",
      "loss: 1.070507  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 1.044554 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.027355  [   64/ 2000]\n",
      "loss: 1.060597  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.033070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.006080  [   64/ 2000]\n",
      "loss: 1.050705  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.7%, Avg loss: 1.025524 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.988846  [   64/ 2000]\n",
      "loss: 1.043953  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.4%, Avg loss: 1.020293 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.974786  [   64/ 2000]\n",
      "loss: 1.036566  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.015958 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.963016  [   64/ 2000]\n",
      "loss: 1.031253  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.012457 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.952138  [   64/ 2000]\n",
      "loss: 1.024865  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.8%, Avg loss: 1.010504 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.944306  [   64/ 2000]\n",
      "loss: 1.018610  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 1.008110 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.935472  [   64/ 2000]\n",
      "loss: 1.013523  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.3%, Avg loss: 1.006286 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.927563  [   64/ 2000]\n",
      "loss: 1.008613  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.004472 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.920944  [   64/ 2000]\n",
      "loss: 1.003746  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.003127 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.913566  [   64/ 2000]\n",
      "loss: 0.998401  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.001567 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.907165  [   64/ 2000]\n",
      "loss: 0.993182  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.000578 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.900001  [   64/ 2000]\n",
      "loss: 0.988508  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.3%, Avg loss: 0.999416 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.893466  [   64/ 2000]\n",
      "loss: 0.983319  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.4%, Avg loss: 0.998206 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.887399  [   64/ 2000]\n",
      "loss: 0.978504  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.997160 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.880853  [   64/ 2000]\n",
      "loss: 0.973309  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.996140 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.874652  [   64/ 2000]\n",
      "loss: 0.967739  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.995352 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.869101  [   64/ 2000]\n",
      "loss: 0.963099  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 0.994371 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.863864  [   64/ 2000]\n",
      "loss: 0.956876  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.1%, Avg loss: 0.994761 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.859437  [   64/ 2000]\n",
      "loss: 0.951165  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.9%, Avg loss: 0.993933 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.852633  [   64/ 2000]\n",
      "loss: 0.945752  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.993406 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.846435  [   64/ 2000]\n",
      "loss: 0.939731  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.992626 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.840193  [   64/ 2000]\n",
      "loss: 0.933580  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.992738 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.834346  [   64/ 2000]\n",
      "loss: 0.928019  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.992036 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.828675  [   64/ 2000]\n",
      "loss: 0.921826  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.990997 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.821357  [   64/ 2000]\n",
      "loss: 0.915428  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.991879 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.814838  [   64/ 2000]\n",
      "loss: 0.909480  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 0.989790 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.806680  [   64/ 2000]\n",
      "loss: 0.902342  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 0.990177 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.800007  [   64/ 2000]\n",
      "loss: 0.895740  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.990113 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.794619  [   64/ 2000]\n",
      "loss: 0.889192  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 0.991716 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.790689  [   64/ 2000]\n",
      "loss: 0.881802  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.991595 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.780309  [   64/ 2000]\n",
      "loss: 0.875332  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 0.992713 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.775166  [   64/ 2000]\n",
      "loss: 0.868172  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.991948 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.765187  [   64/ 2000]\n",
      "loss: 0.860585  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 0.998714 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.762978  [   64/ 2000]\n",
      "loss: 0.851030  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 0.995441 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.748254  [   64/ 2000]\n",
      "loss: 0.844820  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.993014 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.738416  [   64/ 2000]\n",
      "loss: 0.837433  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 0.997998 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.736171  [   64/ 2000]\n",
      "loss: 0.826348  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.005909 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.733413  [   64/ 2000]\n",
      "loss: 0.818622  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.000055 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.718245  [   64/ 2000]\n",
      "loss: 0.814099  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.990440 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.702598  [   64/ 2000]\n",
      "loss: 0.805454  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.012205 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.712034  [   64/ 2000]\n",
      "loss: 0.796746  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.995028 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.691728  [   64/ 2000]\n",
      "loss: 0.788843  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.987610 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.679947  [   64/ 2000]\n",
      "loss: 0.785657  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.998099 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.676877  [   64/ 2000]\n",
      "loss: 0.767300  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.013525 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.677701  [   64/ 2000]\n",
      "loss: 0.763807  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.4%, Avg loss: 0.991843 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.656650  [   64/ 2000]\n",
      "loss: 0.761051  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.6%, Avg loss: 0.994539 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.650979  [   64/ 2000]\n",
      "loss: 0.744456  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.2%, Avg loss: 1.015075 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.648343  [   64/ 2000]\n",
      "loss: 0.724314  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.006741 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.635907  [   64/ 2000]\n",
      "loss: 0.760922  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.077573 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.703522  [   64/ 2000]\n",
      "loss: 0.694851  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.141697 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.763294  [   64/ 2000]\n",
      "loss: 0.685567  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 1.085105 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.652381  [   64/ 2000]\n",
      "loss: 0.667871  [ 1344/ 2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.071417 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.624628  [   64/ 2000]\n",
      "loss: 0.661609  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.041389 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.593108  [   64/ 2000]\n",
      "loss: 0.697009  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 48.9%, Avg loss: 1.100853 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.631196  [   64/ 2000]\n",
      "loss: 0.693706  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 1.109333 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.622581  [   64/ 2000]\n",
      "loss: 0.624121  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: 1.079050 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.581552  [   64/ 2000]\n",
      "loss: 0.677989  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.9%, Avg loss: 1.092566 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.571594  [   64/ 2000]\n",
      "loss: 0.727678  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.107261 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.584768  [   64/ 2000]\n",
      "loss: 0.684843  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.098774 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.550160  [   64/ 2000]\n",
      "loss: 0.582021  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.089286 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.534919  [   64/ 2000]\n",
      "loss: 0.779994  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.105907 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.558489  [   64/ 2000]\n",
      "loss: 0.634566  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.0%, Avg loss: 1.073928 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.515498  [   64/ 2000]\n",
      "loss: 0.584949  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.090340 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.511808  [   64/ 2000]\n",
      "loss: 0.514040  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.202805 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.618590  [   64/ 2000]\n",
      "loss: 0.563386  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.085430 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.483606  [   64/ 2000]\n",
      "loss: 0.524107  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.085021 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.492477  [   64/ 2000]\n",
      "loss: 0.472835  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.7%, Avg loss: 1.085521 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.467754  [   64/ 2000]\n",
      "loss: 0.514438  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.5%, Avg loss: 1.114776 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.473630  [   64/ 2000]\n",
      "loss: 0.655677  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.160746 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.485907  [   64/ 2000]\n",
      "loss: 0.624785  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.5%, Avg loss: 1.165564 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.478122  [   64/ 2000]\n",
      "loss: 0.540843  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.087376 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.497143  [   64/ 2000]\n",
      "loss: 0.407618  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.195348 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.493291  [   64/ 2000]\n",
      "loss: 0.393106  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.201727 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.486849  [   64/ 2000]\n",
      "loss: 0.568195  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.140168 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.399534  [   64/ 2000]\n",
      "loss: 0.392742  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.147749 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.400073  [   64/ 2000]\n",
      "loss: 0.340051  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.215032 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.426844  [   64/ 2000]\n",
      "loss: 0.351006  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.165829 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.394187  [   64/ 2000]\n",
      "loss: 0.367885  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.145585 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.443689  [   64/ 2000]\n",
      "loss: 0.332015  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.170747 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.396318  [   64/ 2000]\n",
      "loss: 0.575888  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.151724 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.447544  [   64/ 2000]\n",
      "loss: 0.317881  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.6%, Avg loss: 1.141464 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.351105  [   64/ 2000]\n",
      "loss: 0.522244  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.4%, Avg loss: 1.146472 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.402365  [   64/ 2000]\n",
      "loss: 0.317681  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.200366 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.370990  [   64/ 2000]\n",
      "loss: 0.285141  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.9%, Avg loss: 1.218872 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.323799  [   64/ 2000]\n",
      "loss: 0.367852  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 1.147485 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.301678  [   64/ 2000]\n",
      "loss: 0.307354  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.276411 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.368285  [   64/ 2000]\n",
      "loss: 0.228075  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 1.235301 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.326295  [   64/ 2000]\n",
      "loss: 0.294316  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.209935 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.306420  [   64/ 2000]\n",
      "loss: 0.740261  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.187890 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.298044  [   64/ 2000]\n",
      "loss: 0.553722  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.348074 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.381501  [   64/ 2000]\n",
      "loss: 0.259810  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 1.147609 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.243992  [   64/ 2000]\n",
      "loss: 0.562075  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.361586 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.380982  [   64/ 2000]\n",
      "loss: 0.226199  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.232293 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.235194  [   64/ 2000]\n",
      "loss: 0.156649  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.331944 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.250525  [   64/ 2000]\n",
      "loss: 0.314730  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.218511 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.205705  [   64/ 2000]\n",
      "loss: 0.184751  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 1.244052 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.378669  [   64/ 2000]\n",
      "loss: 0.304458  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.198201 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.231318  [   64/ 2000]\n",
      "loss: 0.181479  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 1.295074 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1 + passed}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "passed = passed + epochs\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8fc6d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.220762  [   64/ 2000]\n",
      "loss: 0.125111  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.397122 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.306219  [   64/ 2000]\n",
      "loss: 0.328828  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.226441 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.230715  [   64/ 2000]\n",
      "loss: 0.158265  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.1%, Avg loss: 1.300583 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.224769  [   64/ 2000]\n",
      "loss: 0.137153  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.4%, Avg loss: 1.340072 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.227912  [   64/ 2000]\n",
      "loss: 0.107555  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 51.7%, Avg loss: 1.718905 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.384697  [   64/ 2000]\n",
      "loss: 0.175838  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.257272 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.250371  [   64/ 2000]\n",
      "loss: 0.103714  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.557725 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.332381  [   64/ 2000]\n",
      "loss: 0.093809  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.292918 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.130379  [   64/ 2000]\n",
      "loss: 0.102774  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.1%, Avg loss: 1.327880 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.120502  [   64/ 2000]\n",
      "loss: 0.077261  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 43.0%, Avg loss: 1.825018 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 1.030000  [   64/ 2000]\n",
      "loss: 0.321370  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.172096 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.266458  [   64/ 2000]\n",
      "loss: 0.254398  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.233770 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.150243  [   64/ 2000]\n",
      "loss: 0.173326  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 1.279998 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.148680  [   64/ 2000]\n",
      "loss: 0.083435  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 52.7%, Avg loss: 1.622001 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.235532  [   64/ 2000]\n",
      "loss: 0.143538  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.1%, Avg loss: 1.366218 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.123202  [   64/ 2000]\n",
      "loss: 0.132381  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.3%, Avg loss: 1.330273 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.102212  [   64/ 2000]\n",
      "loss: 0.080164  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 1.343984 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.075212  [   64/ 2000]\n",
      "loss: 0.063381  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 54.2%, Avg loss: 1.504636 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.121035  [   64/ 2000]\n",
      "loss: 0.167779  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.350420 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.096056  [   64/ 2000]\n",
      "loss: 0.080485  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.7%, Avg loss: 1.363806 \n",
      "\n",
      "Done!\n",
      "Start\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.085694  [   64/ 2000]\n",
      "loss: 2.198422  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.785436 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.792038  [   64/ 2000]\n",
      "loss: 0.177080  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.242385 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.103793  [   64/ 2000]\n",
      "loss: 0.086602  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 1.316177 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.076768  [   64/ 2000]\n",
      "loss: 0.057310  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.9%, Avg loss: 1.378758 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.060462  [   64/ 2000]\n",
      "loss: 0.069554  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.361455 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.080039  [   64/ 2000]\n",
      "loss: 0.046803  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 55.0%, Avg loss: 1.535119 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.146721  [   64/ 2000]\n",
      "loss: 0.053514  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.402881 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.047707  [   64/ 2000]\n",
      "loss: 0.035292  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.1%, Avg loss: 1.488476 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.037686  [   64/ 2000]\n",
      "loss: 0.953806  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.0%, Avg loss: 1.477837 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.077476  [   64/ 2000]\n",
      "loss: 0.070142  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.442023 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.043436  [   64/ 2000]\n",
      "loss: 0.035718  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 1.495977 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.035399  [   64/ 2000]\n",
      "loss: 0.082556  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.426645 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.042934  [   64/ 2000]\n",
      "loss: 0.052906  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.447718 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.036967  [   64/ 2000]\n",
      "loss: 0.028573  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.513660 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.031087  [   64/ 2000]\n",
      "loss: 0.048518  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.532844 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.035903  [   64/ 2000]\n",
      "loss: 0.026010  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.582512 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.024720  [   64/ 2000]\n",
      "loss: 0.224395  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 2.362649 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.774541  [   64/ 2000]\n",
      "loss: 0.490719  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.330492 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.086307  [   64/ 2000]\n",
      "loss: 0.144293  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.402268 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.045235  [   64/ 2000]\n",
      "loss: 0.064087  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 1.526013 \n",
      "\n",
      "Done!\n",
      "Start\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.045433  [   64/ 2000]\n",
      "loss: 0.031179  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 1.501097 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.025372  [   64/ 2000]\n",
      "loss: 0.024199  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.542373 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.021608  [   64/ 2000]\n",
      "loss: 0.028770  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 1.778706 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.168432  [   64/ 2000]\n",
      "loss: 0.039396  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 1.544096 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.038384  [   64/ 2000]\n",
      "loss: 0.028330  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.3%, Avg loss: 1.612561 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.018242  [   64/ 2000]\n",
      "loss: 0.017773  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.605330 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.016333  [   64/ 2000]\n",
      "loss: 0.015374  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.640586 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.014551  [   64/ 2000]\n",
      "loss: 0.122573  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 1.427356 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.052588  [   64/ 2000]\n",
      "loss: 0.067033  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 58.6%, Avg loss: 1.485295 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.035259  [   64/ 2000]\n",
      "loss: 0.030630  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 1.586467 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.027021  [   64/ 2000]\n",
      "loss: 0.019096  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.620949 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.019345  [   64/ 2000]\n",
      "loss: 0.015736  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 1.902218 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.123616  [   64/ 2000]\n",
      "loss: 0.013948  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 1.687583 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.013104  [   64/ 2000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.012900  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.699887 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.012329  [   64/ 2000]\n",
      "loss: 0.011411  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.720372 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.011482  [   64/ 2000]\n",
      "loss: 0.010717  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 1.745284 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.010612  [   64/ 2000]\n",
      "loss: 0.010027  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.774926 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.009801  [   64/ 2000]\n",
      "loss: 0.492412  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.430533 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.237911  [   64/ 2000]\n",
      "loss: 0.064682  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 57.8%, Avg loss: 1.516688 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.072861  [   64/ 2000]\n",
      "loss: 0.022256  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.7%, Avg loss: 1.578821 \n",
      "\n",
      "Done!\n",
      "Start\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.018577  [   64/ 2000]\n",
      "loss: 0.015902  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.655080 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.014863  [   64/ 2000]\n",
      "loss: 0.012883  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.685042 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.011570  [   64/ 2000]\n",
      "loss: 0.011040  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 1.726567 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.010277  [   64/ 2000]\n",
      "loss: 0.009810  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.757623 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.009377  [   64/ 2000]\n",
      "loss: 0.008890  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.787268 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.008623  [   64/ 2000]\n",
      "loss: 0.008209  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.812337 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.008050  [   64/ 2000]\n",
      "loss: 0.007643  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.835466 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.007553  [   64/ 2000]\n",
      "loss: 0.007162  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.857359 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.007135  [   64/ 2000]\n",
      "loss: 0.006756  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.876366 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.006752  [   64/ 2000]\n",
      "loss: 0.006427  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.895203 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.006417  [   64/ 2000]\n",
      "loss: 0.006093  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.912578 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.006122  [   64/ 2000]\n",
      "loss: 0.005813  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.927390 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.005850  [   64/ 2000]\n",
      "loss: 0.005561  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.944387 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.005582  [   64/ 2000]\n",
      "loss: 0.005332  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.3%, Avg loss: 1.956880 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.005355  [   64/ 2000]\n",
      "loss: 0.005129  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.972040 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.005130  [   64/ 2000]\n",
      "loss: 0.004930  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.2%, Avg loss: 1.985455 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.004941  [   64/ 2000]\n",
      "loss: 0.004750  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 1.997465 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.004772  [   64/ 2000]\n",
      "loss: 0.004585  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.009061 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.004599  [   64/ 2000]\n",
      "loss: 0.004435  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.021679 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.004434  [   64/ 2000]\n",
      "loss: 0.004291  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 2.032881 \n",
      "\n",
      "Done!\n",
      "Start\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.004292  [   64/ 2000]\n",
      "loss: 0.004147  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.042290 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.004159  [   64/ 2000]\n",
      "loss: 0.004032  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.0%, Avg loss: 2.053068 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.004038  [   64/ 2000]\n",
      "loss: 0.003919  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.064070 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.003912  [   64/ 2000]\n",
      "loss: 0.003800  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.072243 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.003804  [   64/ 2000]\n",
      "loss: 0.003691  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.081728 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.003694  [   64/ 2000]\n",
      "loss: 0.003593  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.091017 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.003594  [   64/ 2000]\n",
      "loss: 0.003505  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.099294 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.003496  [   64/ 2000]\n",
      "loss: 0.003418  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 2.107192 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.003404  [   64/ 2000]\n",
      "loss: 0.003330  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 2.115905 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.003314  [   64/ 2000]\n",
      "loss: 0.003255  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 2.124161 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.003231  [   64/ 2000]\n",
      "loss: 0.003175  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.8%, Avg loss: 2.131805 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.003149  [   64/ 2000]\n",
      "loss: 0.003107  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.139503 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.003073  [   64/ 2000]\n",
      "loss: 0.003033  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.146634 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.003001  [   64/ 2000]\n",
      "loss: 0.002962  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.154005 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.002928  [   64/ 2000]\n",
      "loss: 0.002895  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 2.161312 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.002863  [   64/ 2000]\n",
      "loss: 0.002833  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 2.168268 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.002799  [   64/ 2000]\n",
      "loss: 0.002773  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 2.175158 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.002739  [   64/ 2000]\n",
      "loss: 0.002722  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 2.181397 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.002681  [   64/ 2000]\n",
      "loss: 0.002659  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 2.187656 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.002624  [   64/ 2000]\n",
      "loss: 0.002604  [ 1344/ 2000]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 2.194226 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for stuff in range(5):\n",
    "    epochs = 20\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=1e-2, dampening=1e-3)\n",
    "    print(\"Start\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1 + passed}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loop(test_dataloader, model, loss_fn)\n",
    "    passed = passed + epochs\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da9332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
