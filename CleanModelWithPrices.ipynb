{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27033b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"10SecondStepPriceEvolution2.csv\")\n",
    "df[\"F10\"] = df[\"F10\"] - df[\"Cur\"]\n",
    "df[\"P10\"] = df[\"P10\"] - df[\"Cur\"]\n",
    "df[\"P20\"] = df[\"P20\"] - df[\"Cur\"]\n",
    "df[\"P30\"] = df[\"P30\"] - df[\"Cur\"]\n",
    "df[\"P40\"] = df[\"P40\"] - df[\"Cur\"]\n",
    "df[\"P50\"] = df[\"P50\"] - df[\"Cur\"]\n",
    "df[\"P60\"] = df[\"P60\"] - df[\"Cur\"]\n",
    "df.drop('Cur', axis=1, inplace=True)\n",
    "df['F10'] = df['F10'].apply(lambda x: 1 if x >= 1 else -1 if x <= -1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccbab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = df[df['F10'] == 0]\n",
    "ones  = df[df['F10'] == 1]\n",
    "negas = df[df['F10'] == -1]\n",
    "zeros = zeros.sample(frac=1).reset_index(drop=True)\n",
    "zeros = zeros[:15000]\n",
    "df = pd.concat([zeros, ones, negas])\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c793c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df.head(40000)\n",
    "test_dataset = df.tail(df.shape[0] - 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218819b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomPriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, labels, transform=None, target_transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = list(self.dataframe.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fcf882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "trnlbl = train_dataset['F10'] + 1\n",
    "trnset = train_dataset.drop('F10', axis=1)\n",
    "trainPrice = CustomPriceDataset(trnset, trnlbl, torch.FloatTensor, Lambda(lambda y: torch.zeros(3, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)))\n",
    "train_dataloader = DataLoader(trainPrice, batch_size=64)\n",
    "\n",
    "tstlbl = test_dataset['F10'] + 1\n",
    "tstset = test_dataset.drop('F10', axis=1)\n",
    "testPrice = CustomPriceDataset(tstset, tstlbl, torch.FloatTensor)\n",
    "test_dataloader = DataLoader(testPrice, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88071548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(6, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b873fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7363e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "passed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55af0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=1e-2, dampening=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae02eb13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.101977  [   64/40000]\n",
      "loss: 1.073623  [ 6464/40000]\n",
      "loss: 1.060048  [12864/40000]\n",
      "loss: 1.053258  [19264/40000]\n",
      "loss: 1.071350  [25664/40000]\n",
      "loss: 1.061059  [32064/40000]\n",
      "loss: 1.076380  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.071490 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.112722  [   64/40000]\n",
      "loss: 1.071458  [ 6464/40000]\n",
      "loss: 1.045130  [12864/40000]\n",
      "loss: 1.042927  [19264/40000]\n",
      "loss: 1.064198  [25664/40000]\n",
      "loss: 1.050069  [32064/40000]\n",
      "loss: 1.071813  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 1.067199 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.116194  [   64/40000]\n",
      "loss: 1.074010  [ 6464/40000]\n",
      "loss: 1.041106  [12864/40000]\n",
      "loss: 1.040251  [19264/40000]\n",
      "loss: 1.061234  [25664/40000]\n",
      "loss: 1.043204  [32064/40000]\n",
      "loss: 1.070564  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.064891 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.115977  [   64/40000]\n",
      "loss: 1.074812  [ 6464/40000]\n",
      "loss: 1.038606  [12864/40000]\n",
      "loss: 1.039667  [19264/40000]\n",
      "loss: 1.059378  [25664/40000]\n",
      "loss: 1.038437  [32064/40000]\n",
      "loss: 1.069849  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.063102 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.114461  [   64/40000]\n",
      "loss: 1.075021  [ 6464/40000]\n",
      "loss: 1.037213  [12864/40000]\n",
      "loss: 1.038971  [19264/40000]\n",
      "loss: 1.057928  [25664/40000]\n",
      "loss: 1.035027  [32064/40000]\n",
      "loss: 1.069216  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.061534 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.112736  [   64/40000]\n",
      "loss: 1.075011  [ 6464/40000]\n",
      "loss: 1.035962  [12864/40000]\n",
      "loss: 1.038081  [19264/40000]\n",
      "loss: 1.056644  [25664/40000]\n",
      "loss: 1.032641  [32064/40000]\n",
      "loss: 1.068034  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 44.6%, Avg loss: 1.059846 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.111467  [   64/40000]\n",
      "loss: 1.074378  [ 6464/40000]\n",
      "loss: 1.035199  [12864/40000]\n",
      "loss: 1.036579  [19264/40000]\n",
      "loss: 1.055807  [25664/40000]\n",
      "loss: 1.030358  [32064/40000]\n",
      "loss: 1.066791  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.058183 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.110261  [   64/40000]\n",
      "loss: 1.073865  [ 6464/40000]\n",
      "loss: 1.034288  [12864/40000]\n",
      "loss: 1.034744  [19264/40000]\n",
      "loss: 1.055336  [25664/40000]\n",
      "loss: 1.028579  [32064/40000]\n",
      "loss: 1.064609  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.056439 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.109108  [   64/40000]\n",
      "loss: 1.073164  [ 6464/40000]\n",
      "loss: 1.033668  [12864/40000]\n",
      "loss: 1.032666  [19264/40000]\n",
      "loss: 1.054775  [25664/40000]\n",
      "loss: 1.026819  [32064/40000]\n",
      "loss: 1.062907  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.054607 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.107061  [   64/40000]\n",
      "loss: 1.072370  [ 6464/40000]\n",
      "loss: 1.033150  [12864/40000]\n",
      "loss: 1.030644  [19264/40000]\n",
      "loss: 1.054488  [25664/40000]\n",
      "loss: 1.025646  [32064/40000]\n",
      "loss: 1.059975  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.052819 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 1.105813  [   64/40000]\n",
      "loss: 1.071944  [ 6464/40000]\n",
      "loss: 1.032525  [12864/40000]\n",
      "loss: 1.027832  [19264/40000]\n",
      "loss: 1.054403  [25664/40000]\n",
      "loss: 1.024748  [32064/40000]\n",
      "loss: 1.056985  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.050927 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.104864  [   64/40000]\n",
      "loss: 1.071050  [ 6464/40000]\n",
      "loss: 1.031783  [12864/40000]\n",
      "loss: 1.025423  [19264/40000]\n",
      "loss: 1.053973  [25664/40000]\n",
      "loss: 1.023793  [32064/40000]\n",
      "loss: 1.054020  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.049064 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.104392  [   64/40000]\n",
      "loss: 1.070647  [ 6464/40000]\n",
      "loss: 1.031626  [12864/40000]\n",
      "loss: 1.022903  [19264/40000]\n",
      "loss: 1.054101  [25664/40000]\n",
      "loss: 1.022391  [32064/40000]\n",
      "loss: 1.050925  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.047385 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 1.103109  [   64/40000]\n",
      "loss: 1.070658  [ 6464/40000]\n",
      "loss: 1.031935  [12864/40000]\n",
      "loss: 1.020445  [19264/40000]\n",
      "loss: 1.054856  [25664/40000]\n",
      "loss: 1.021146  [32064/40000]\n",
      "loss: 1.047634  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.045764 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.102337  [   64/40000]\n",
      "loss: 1.070007  [ 6464/40000]\n",
      "loss: 1.031870  [12864/40000]\n",
      "loss: 1.016987  [19264/40000]\n",
      "loss: 1.054980  [25664/40000]\n",
      "loss: 1.019757  [32064/40000]\n",
      "loss: 1.044797  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.044280 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.102312  [   64/40000]\n",
      "loss: 1.069579  [ 6464/40000]\n",
      "loss: 1.031901  [12864/40000]\n",
      "loss: 1.015412  [19264/40000]\n",
      "loss: 1.056106  [25664/40000]\n",
      "loss: 1.018734  [32064/40000]\n",
      "loss: 1.041886  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.042946 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 1.102066  [   64/40000]\n",
      "loss: 1.068603  [ 6464/40000]\n",
      "loss: 1.031499  [12864/40000]\n",
      "loss: 1.013215  [19264/40000]\n",
      "loss: 1.057844  [25664/40000]\n",
      "loss: 1.017104  [32064/40000]\n",
      "loss: 1.039864  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.041862 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.102116  [   64/40000]\n",
      "loss: 1.067876  [ 6464/40000]\n",
      "loss: 1.032149  [12864/40000]\n",
      "loss: 1.011107  [19264/40000]\n",
      "loss: 1.058976  [25664/40000]\n",
      "loss: 1.015467  [32064/40000]\n",
      "loss: 1.037084  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.040718 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.102821  [   64/40000]\n",
      "loss: 1.067273  [ 6464/40000]\n",
      "loss: 1.032173  [12864/40000]\n",
      "loss: 1.008426  [19264/40000]\n",
      "loss: 1.059772  [25664/40000]\n",
      "loss: 1.014226  [32064/40000]\n",
      "loss: 1.035320  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.039802 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.103194  [   64/40000]\n",
      "loss: 1.066038  [ 6464/40000]\n",
      "loss: 1.033720  [12864/40000]\n",
      "loss: 1.006773  [19264/40000]\n",
      "loss: 1.059645  [25664/40000]\n",
      "loss: 1.013047  [32064/40000]\n",
      "loss: 1.033667  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.039113 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 1.103584  [   64/40000]\n",
      "loss: 1.064736  [ 6464/40000]\n",
      "loss: 1.034684  [12864/40000]\n",
      "loss: 1.006011  [19264/40000]\n",
      "loss: 1.060076  [25664/40000]\n",
      "loss: 1.011697  [32064/40000]\n",
      "loss: 1.032505  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.038428 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.103757  [   64/40000]\n",
      "loss: 1.063975  [ 6464/40000]\n",
      "loss: 1.035026  [12864/40000]\n",
      "loss: 1.004540  [19264/40000]\n",
      "loss: 1.059717  [25664/40000]\n",
      "loss: 1.010490  [32064/40000]\n",
      "loss: 1.032677  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.037877 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 1.104042  [   64/40000]\n",
      "loss: 1.063872  [ 6464/40000]\n",
      "loss: 1.035012  [12864/40000]\n",
      "loss: 1.002214  [19264/40000]\n",
      "loss: 1.059368  [25664/40000]\n",
      "loss: 1.008526  [32064/40000]\n",
      "loss: 1.031482  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.037593 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.103242  [   64/40000]\n",
      "loss: 1.062482  [ 6464/40000]\n",
      "loss: 1.036742  [12864/40000]\n",
      "loss: 1.001131  [19264/40000]\n",
      "loss: 1.059224  [25664/40000]\n",
      "loss: 1.007228  [32064/40000]\n",
      "loss: 1.030865  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.037077 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 1.103403  [   64/40000]\n",
      "loss: 1.061393  [ 6464/40000]\n",
      "loss: 1.037001  [12864/40000]\n",
      "loss: 0.999499  [19264/40000]\n",
      "loss: 1.059349  [25664/40000]\n",
      "loss: 1.007029  [32064/40000]\n",
      "loss: 1.030573  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.036699 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 1.104441  [   64/40000]\n",
      "loss: 1.061186  [ 6464/40000]\n",
      "loss: 1.036697  [12864/40000]\n",
      "loss: 0.998517  [19264/40000]\n",
      "loss: 1.058327  [25664/40000]\n",
      "loss: 1.005875  [32064/40000]\n",
      "loss: 1.030123  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.036223 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 1.104295  [   64/40000]\n",
      "loss: 1.060497  [ 6464/40000]\n",
      "loss: 1.037173  [12864/40000]\n",
      "loss: 0.996707  [19264/40000]\n",
      "loss: 1.057888  [25664/40000]\n",
      "loss: 1.004618  [32064/40000]\n",
      "loss: 1.029109  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.8%, Avg loss: 1.035838 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.104613  [   64/40000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.060377  [ 6464/40000]\n",
      "loss: 1.036769  [12864/40000]\n",
      "loss: 0.995795  [19264/40000]\n",
      "loss: 1.057732  [25664/40000]\n",
      "loss: 1.004605  [32064/40000]\n",
      "loss: 1.029313  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.035631 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.104116  [   64/40000]\n",
      "loss: 1.059618  [ 6464/40000]\n",
      "loss: 1.037495  [12864/40000]\n",
      "loss: 0.994217  [19264/40000]\n",
      "loss: 1.056635  [25664/40000]\n",
      "loss: 1.003960  [32064/40000]\n",
      "loss: 1.028729  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.035336 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 1.103996  [   64/40000]\n",
      "loss: 1.059138  [ 6464/40000]\n",
      "loss: 1.037224  [12864/40000]\n",
      "loss: 0.993220  [19264/40000]\n",
      "loss: 1.056553  [25664/40000]\n",
      "loss: 1.002808  [32064/40000]\n",
      "loss: 1.027637  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.034962 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 1.104065  [   64/40000]\n",
      "loss: 1.058846  [ 6464/40000]\n",
      "loss: 1.036875  [12864/40000]\n",
      "loss: 0.992391  [19264/40000]\n",
      "loss: 1.056062  [25664/40000]\n",
      "loss: 1.002495  [32064/40000]\n",
      "loss: 1.027291  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.034726 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 1.103195  [   64/40000]\n",
      "loss: 1.059327  [ 6464/40000]\n",
      "loss: 1.039028  [12864/40000]\n",
      "loss: 0.991430  [19264/40000]\n",
      "loss: 1.054536  [25664/40000]\n",
      "loss: 1.001647  [32064/40000]\n",
      "loss: 1.027387  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.034498 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 1.102962  [   64/40000]\n",
      "loss: 1.058510  [ 6464/40000]\n",
      "loss: 1.039342  [12864/40000]\n",
      "loss: 0.990720  [19264/40000]\n",
      "loss: 1.054240  [25664/40000]\n",
      "loss: 1.000987  [32064/40000]\n",
      "loss: 1.026661  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.034157 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.101600  [   64/40000]\n",
      "loss: 1.058297  [ 6464/40000]\n",
      "loss: 1.039099  [12864/40000]\n",
      "loss: 0.990372  [19264/40000]\n",
      "loss: 1.054033  [25664/40000]\n",
      "loss: 0.999843  [32064/40000]\n",
      "loss: 1.026435  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.034064 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.102304  [   64/40000]\n",
      "loss: 1.057994  [ 6464/40000]\n",
      "loss: 1.038808  [12864/40000]\n",
      "loss: 0.990196  [19264/40000]\n",
      "loss: 1.052899  [25664/40000]\n",
      "loss: 1.000087  [32064/40000]\n",
      "loss: 1.025545  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.033749 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.101667  [   64/40000]\n",
      "loss: 1.057849  [ 6464/40000]\n",
      "loss: 1.038888  [12864/40000]\n",
      "loss: 0.990394  [19264/40000]\n",
      "loss: 1.051657  [25664/40000]\n",
      "loss: 0.999222  [32064/40000]\n",
      "loss: 1.024864  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.033574 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.101384  [   64/40000]\n",
      "loss: 1.057869  [ 6464/40000]\n",
      "loss: 1.040190  [12864/40000]\n",
      "loss: 0.988988  [19264/40000]\n",
      "loss: 1.051490  [25664/40000]\n",
      "loss: 0.999029  [32064/40000]\n",
      "loss: 1.024814  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.033496 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 1.101395  [   64/40000]\n",
      "loss: 1.057613  [ 6464/40000]\n",
      "loss: 1.039460  [12864/40000]\n",
      "loss: 0.988074  [19264/40000]\n",
      "loss: 1.049721  [25664/40000]\n",
      "loss: 0.998797  [32064/40000]\n",
      "loss: 1.024132  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.033204 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 1.100480  [   64/40000]\n",
      "loss: 1.057929  [ 6464/40000]\n",
      "loss: 1.039377  [12864/40000]\n",
      "loss: 0.986878  [19264/40000]\n",
      "loss: 1.049087  [25664/40000]\n",
      "loss: 0.998452  [32064/40000]\n",
      "loss: 1.023566  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.032966 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.099915  [   64/40000]\n",
      "loss: 1.057603  [ 6464/40000]\n",
      "loss: 1.039454  [12864/40000]\n",
      "loss: 0.986870  [19264/40000]\n",
      "loss: 1.048195  [25664/40000]\n",
      "loss: 0.997878  [32064/40000]\n",
      "loss: 1.022515  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.032832 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 1.099233  [   64/40000]\n",
      "loss: 1.057491  [ 6464/40000]\n",
      "loss: 1.038795  [12864/40000]\n",
      "loss: 0.987569  [19264/40000]\n",
      "loss: 1.047490  [25664/40000]\n",
      "loss: 0.997566  [32064/40000]\n",
      "loss: 1.022570  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.032743 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 1.099093  [   64/40000]\n",
      "loss: 1.057570  [ 6464/40000]\n",
      "loss: 1.039337  [12864/40000]\n",
      "loss: 0.986046  [19264/40000]\n",
      "loss: 1.048135  [25664/40000]\n",
      "loss: 0.996581  [32064/40000]\n",
      "loss: 1.022217  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.032544 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.098210  [   64/40000]\n",
      "loss: 1.057112  [ 6464/40000]\n",
      "loss: 1.039474  [12864/40000]\n",
      "loss: 0.985499  [19264/40000]\n",
      "loss: 1.047068  [25664/40000]\n",
      "loss: 0.997133  [32064/40000]\n",
      "loss: 1.022354  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.032375 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.097238  [   64/40000]\n",
      "loss: 1.056703  [ 6464/40000]\n",
      "loss: 1.038999  [12864/40000]\n",
      "loss: 0.986031  [19264/40000]\n",
      "loss: 1.045292  [25664/40000]\n",
      "loss: 0.996149  [32064/40000]\n",
      "loss: 1.021307  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.032255 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.096934  [   64/40000]\n",
      "loss: 1.056453  [ 6464/40000]\n",
      "loss: 1.039161  [12864/40000]\n",
      "loss: 0.984595  [19264/40000]\n",
      "loss: 1.044901  [25664/40000]\n",
      "loss: 0.994960  [32064/40000]\n",
      "loss: 1.020442  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.031945 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 1.096807  [   64/40000]\n",
      "loss: 1.056206  [ 6464/40000]\n",
      "loss: 1.039681  [12864/40000]\n",
      "loss: 0.983917  [19264/40000]\n",
      "loss: 1.044244  [25664/40000]\n",
      "loss: 0.994465  [32064/40000]\n",
      "loss: 1.020082  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 1.031873 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.096388  [   64/40000]\n",
      "loss: 1.056039  [ 6464/40000]\n",
      "loss: 1.038684  [12864/40000]\n",
      "loss: 0.983248  [19264/40000]\n",
      "loss: 1.042610  [25664/40000]\n",
      "loss: 0.993564  [32064/40000]\n",
      "loss: 1.019842  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.031902 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.095691  [   64/40000]\n",
      "loss: 1.055288  [ 6464/40000]\n",
      "loss: 1.038316  [12864/40000]\n",
      "loss: 0.982738  [19264/40000]\n",
      "loss: 1.042438  [25664/40000]\n",
      "loss: 0.993293  [32064/40000]\n",
      "loss: 1.019243  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.031649 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 1.095020  [   64/40000]\n",
      "loss: 1.055208  [ 6464/40000]\n",
      "loss: 1.038186  [12864/40000]\n",
      "loss: 0.983071  [19264/40000]\n",
      "loss: 1.041126  [25664/40000]\n",
      "loss: 0.993376  [32064/40000]\n",
      "loss: 1.019998  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.031420 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 1.094834  [   64/40000]\n",
      "loss: 1.054440  [ 6464/40000]\n",
      "loss: 1.038771  [12864/40000]\n",
      "loss: 0.983695  [19264/40000]\n",
      "loss: 1.041500  [25664/40000]\n",
      "loss: 0.991988  [32064/40000]\n",
      "loss: 1.019161  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.030981 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 1.095016  [   64/40000]\n",
      "loss: 1.053704  [ 6464/40000]\n",
      "loss: 1.038691  [12864/40000]\n",
      "loss: 0.982687  [19264/40000]\n",
      "loss: 1.041194  [25664/40000]\n",
      "loss: 0.992043  [32064/40000]\n",
      "loss: 1.019929  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.030815 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 1.093792  [   64/40000]\n",
      "loss: 1.052682  [ 6464/40000]\n",
      "loss: 1.039430  [12864/40000]\n",
      "loss: 0.982153  [19264/40000]\n",
      "loss: 1.039842  [25664/40000]\n",
      "loss: 0.991326  [32064/40000]\n",
      "loss: 1.019573  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.030587 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 1.094556  [   64/40000]\n",
      "loss: 1.053486  [ 6464/40000]\n",
      "loss: 1.038994  [12864/40000]\n",
      "loss: 0.982297  [19264/40000]\n",
      "loss: 1.037943  [25664/40000]\n",
      "loss: 0.990141  [32064/40000]\n",
      "loss: 1.018547  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.030408 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.093742  [   64/40000]\n",
      "loss: 1.052806  [ 6464/40000]\n",
      "loss: 1.039003  [12864/40000]\n",
      "loss: 0.982559  [19264/40000]\n",
      "loss: 1.036571  [25664/40000]\n",
      "loss: 0.988992  [32064/40000]\n",
      "loss: 1.017042  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.4%, Avg loss: 1.030148 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.093801  [   64/40000]\n",
      "loss: 1.052427  [ 6464/40000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.037549  [12864/40000]\n",
      "loss: 0.981745  [19264/40000]\n",
      "loss: 1.037391  [25664/40000]\n",
      "loss: 0.988265  [32064/40000]\n",
      "loss: 1.016552  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 1.030097 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.092604  [   64/40000]\n",
      "loss: 1.052938  [ 6464/40000]\n",
      "loss: 1.038769  [12864/40000]\n",
      "loss: 0.981405  [19264/40000]\n",
      "loss: 1.035251  [25664/40000]\n",
      "loss: 0.988422  [32064/40000]\n",
      "loss: 1.016902  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.029773 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.092434  [   64/40000]\n",
      "loss: 1.052480  [ 6464/40000]\n",
      "loss: 1.039585  [12864/40000]\n",
      "loss: 0.982541  [19264/40000]\n",
      "loss: 1.035444  [25664/40000]\n",
      "loss: 0.987601  [32064/40000]\n",
      "loss: 1.016609  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 1.029902 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 1.090444  [   64/40000]\n",
      "loss: 1.051877  [ 6464/40000]\n",
      "loss: 1.037334  [12864/40000]\n",
      "loss: 0.982242  [19264/40000]\n",
      "loss: 1.034108  [25664/40000]\n",
      "loss: 0.987583  [32064/40000]\n",
      "loss: 1.017081  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.029671 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.090397  [   64/40000]\n",
      "loss: 1.051768  [ 6464/40000]\n",
      "loss: 1.037967  [12864/40000]\n",
      "loss: 0.981365  [19264/40000]\n",
      "loss: 1.033824  [25664/40000]\n",
      "loss: 0.987695  [32064/40000]\n",
      "loss: 1.015638  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.029454 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.089265  [   64/40000]\n",
      "loss: 1.051025  [ 6464/40000]\n",
      "loss: 1.036024  [12864/40000]\n",
      "loss: 0.982135  [19264/40000]\n",
      "loss: 1.034002  [25664/40000]\n",
      "loss: 0.987293  [32064/40000]\n",
      "loss: 1.016301  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.029322 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 1.088773  [   64/40000]\n",
      "loss: 1.050862  [ 6464/40000]\n",
      "loss: 1.036456  [12864/40000]\n",
      "loss: 0.981246  [19264/40000]\n",
      "loss: 1.032254  [25664/40000]\n",
      "loss: 0.986729  [32064/40000]\n",
      "loss: 1.013621  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 1.028871 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 1.087956  [   64/40000]\n",
      "loss: 1.050416  [ 6464/40000]\n",
      "loss: 1.039068  [12864/40000]\n",
      "loss: 0.982588  [19264/40000]\n",
      "loss: 1.030781  [25664/40000]\n",
      "loss: 0.985959  [32064/40000]\n",
      "loss: 1.012892  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.028894 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 1.087415  [   64/40000]\n",
      "loss: 1.050558  [ 6464/40000]\n",
      "loss: 1.036811  [12864/40000]\n",
      "loss: 0.981509  [19264/40000]\n",
      "loss: 1.030878  [25664/40000]\n",
      "loss: 0.984431  [32064/40000]\n",
      "loss: 1.010820  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.1%, Avg loss: 1.028608 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 1.086528  [   64/40000]\n",
      "loss: 1.048994  [ 6464/40000]\n",
      "loss: 1.033634  [12864/40000]\n",
      "loss: 0.980597  [19264/40000]\n",
      "loss: 1.030083  [25664/40000]\n",
      "loss: 0.985309  [32064/40000]\n",
      "loss: 1.009951  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.028160 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 1.085767  [   64/40000]\n",
      "loss: 1.048497  [ 6464/40000]\n",
      "loss: 1.031940  [12864/40000]\n",
      "loss: 0.981225  [19264/40000]\n",
      "loss: 1.028827  [25664/40000]\n",
      "loss: 0.984229  [32064/40000]\n",
      "loss: 1.008715  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.028277 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 1.085095  [   64/40000]\n",
      "loss: 1.048392  [ 6464/40000]\n",
      "loss: 1.030984  [12864/40000]\n",
      "loss: 0.980513  [19264/40000]\n",
      "loss: 1.027664  [25664/40000]\n",
      "loss: 0.982731  [32064/40000]\n",
      "loss: 1.007876  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.028113 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 1.084043  [   64/40000]\n",
      "loss: 1.047881  [ 6464/40000]\n",
      "loss: 1.028323  [12864/40000]\n",
      "loss: 0.979016  [19264/40000]\n",
      "loss: 1.027499  [25664/40000]\n",
      "loss: 0.982378  [32064/40000]\n",
      "loss: 1.008349  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.027532 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.083974  [   64/40000]\n",
      "loss: 1.048215  [ 6464/40000]\n",
      "loss: 1.030032  [12864/40000]\n",
      "loss: 0.979438  [19264/40000]\n",
      "loss: 1.025917  [25664/40000]\n",
      "loss: 0.982003  [32064/40000]\n",
      "loss: 1.006685  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.027308 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.082746  [   64/40000]\n",
      "loss: 1.047442  [ 6464/40000]\n",
      "loss: 1.028042  [12864/40000]\n",
      "loss: 0.978852  [19264/40000]\n",
      "loss: 1.025558  [25664/40000]\n",
      "loss: 0.980435  [32064/40000]\n",
      "loss: 1.005453  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.027179 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.082399  [   64/40000]\n",
      "loss: 1.045076  [ 6464/40000]\n",
      "loss: 1.026917  [12864/40000]\n",
      "loss: 0.978539  [19264/40000]\n",
      "loss: 1.025592  [25664/40000]\n",
      "loss: 0.979972  [32064/40000]\n",
      "loss: 1.003089  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.027040 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 1.082263  [   64/40000]\n",
      "loss: 1.044929  [ 6464/40000]\n",
      "loss: 1.026670  [12864/40000]\n",
      "loss: 0.978348  [19264/40000]\n",
      "loss: 1.025013  [25664/40000]\n",
      "loss: 0.979106  [32064/40000]\n",
      "loss: 1.002998  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.026892 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.079739  [   64/40000]\n",
      "loss: 1.044715  [ 6464/40000]\n",
      "loss: 1.026083  [12864/40000]\n",
      "loss: 0.978760  [19264/40000]\n",
      "loss: 1.024509  [25664/40000]\n",
      "loss: 0.978827  [32064/40000]\n",
      "loss: 1.001505  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.026954 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.079252  [   64/40000]\n",
      "loss: 1.043250  [ 6464/40000]\n",
      "loss: 1.025049  [12864/40000]\n",
      "loss: 0.978552  [19264/40000]\n",
      "loss: 1.024403  [25664/40000]\n",
      "loss: 0.979380  [32064/40000]\n",
      "loss: 1.000126  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.026677 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 1.078856  [   64/40000]\n",
      "loss: 1.041634  [ 6464/40000]\n",
      "loss: 1.023748  [12864/40000]\n",
      "loss: 0.979097  [19264/40000]\n",
      "loss: 1.022337  [25664/40000]\n",
      "loss: 0.978068  [32064/40000]\n",
      "loss: 0.998134  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.026398 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.078669  [   64/40000]\n",
      "loss: 1.041212  [ 6464/40000]\n",
      "loss: 1.024182  [12864/40000]\n",
      "loss: 0.977119  [19264/40000]\n",
      "loss: 1.022142  [25664/40000]\n",
      "loss: 0.978866  [32064/40000]\n",
      "loss: 0.997394  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.026302 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.076784  [   64/40000]\n",
      "loss: 1.042045  [ 6464/40000]\n",
      "loss: 1.022485  [12864/40000]\n",
      "loss: 0.978468  [19264/40000]\n",
      "loss: 1.018124  [25664/40000]\n",
      "loss: 0.977962  [32064/40000]\n",
      "loss: 0.995225  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.026191 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.075098  [   64/40000]\n",
      "loss: 1.041174  [ 6464/40000]\n",
      "loss: 1.021185  [12864/40000]\n",
      "loss: 0.976940  [19264/40000]\n",
      "loss: 1.018054  [25664/40000]\n",
      "loss: 0.977645  [32064/40000]\n",
      "loss: 0.994262  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.025842 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 1.075558  [   64/40000]\n",
      "loss: 1.041022  [ 6464/40000]\n",
      "loss: 1.019995  [12864/40000]\n",
      "loss: 0.977155  [19264/40000]\n",
      "loss: 1.016325  [25664/40000]\n",
      "loss: 0.977174  [32064/40000]\n",
      "loss: 0.993600  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.025758 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.073882  [   64/40000]\n",
      "loss: 1.040252  [ 6464/40000]\n",
      "loss: 1.022864  [12864/40000]\n",
      "loss: 0.977803  [19264/40000]\n",
      "loss: 1.017712  [25664/40000]\n",
      "loss: 0.976054  [32064/40000]\n",
      "loss: 0.992219  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.025824 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.072777  [   64/40000]\n",
      "loss: 1.039521  [ 6464/40000]\n",
      "loss: 1.022026  [12864/40000]\n",
      "loss: 0.976731  [19264/40000]\n",
      "loss: 1.015628  [25664/40000]\n",
      "loss: 0.973696  [32064/40000]\n",
      "loss: 0.990028  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.025238 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.072352  [   64/40000]\n",
      "loss: 1.038862  [ 6464/40000]\n",
      "loss: 1.020474  [12864/40000]\n",
      "loss: 0.977103  [19264/40000]\n",
      "loss: 1.015505  [25664/40000]\n",
      "loss: 0.973698  [32064/40000]\n",
      "loss: 0.989425  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.025146 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.072470  [   64/40000]\n",
      "loss: 1.037512  [ 6464/40000]\n",
      "loss: 1.021913  [12864/40000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.975053  [19264/40000]\n",
      "loss: 1.015294  [25664/40000]\n",
      "loss: 0.973056  [32064/40000]\n",
      "loss: 0.990105  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.024970 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 1.071898  [   64/40000]\n",
      "loss: 1.037309  [ 6464/40000]\n",
      "loss: 1.020374  [12864/40000]\n",
      "loss: 0.975759  [19264/40000]\n",
      "loss: 1.016638  [25664/40000]\n",
      "loss: 0.973583  [32064/40000]\n",
      "loss: 0.987493  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.024899 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.071307  [   64/40000]\n",
      "loss: 1.035891  [ 6464/40000]\n",
      "loss: 1.021245  [12864/40000]\n",
      "loss: 0.973751  [19264/40000]\n",
      "loss: 1.014394  [25664/40000]\n",
      "loss: 0.972234  [32064/40000]\n",
      "loss: 0.985678  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.024668 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 1.071820  [   64/40000]\n",
      "loss: 1.034457  [ 6464/40000]\n",
      "loss: 1.019244  [12864/40000]\n",
      "loss: 0.975492  [19264/40000]\n",
      "loss: 1.013132  [25664/40000]\n",
      "loss: 0.969952  [32064/40000]\n",
      "loss: 0.983892  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.024586 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 1.070718  [   64/40000]\n",
      "loss: 1.033845  [ 6464/40000]\n",
      "loss: 1.017504  [12864/40000]\n",
      "loss: 0.976345  [19264/40000]\n",
      "loss: 1.012624  [25664/40000]\n",
      "loss: 0.970453  [32064/40000]\n",
      "loss: 0.981907  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.024452 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.069738  [   64/40000]\n",
      "loss: 1.032848  [ 6464/40000]\n",
      "loss: 1.018106  [12864/40000]\n",
      "loss: 0.974551  [19264/40000]\n",
      "loss: 1.011790  [25664/40000]\n",
      "loss: 0.968007  [32064/40000]\n",
      "loss: 0.981525  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.024033 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 1.068651  [   64/40000]\n",
      "loss: 1.032204  [ 6464/40000]\n",
      "loss: 1.017541  [12864/40000]\n",
      "loss: 0.974161  [19264/40000]\n",
      "loss: 1.011271  [25664/40000]\n",
      "loss: 0.969475  [32064/40000]\n",
      "loss: 0.980862  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.024312 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.068251  [   64/40000]\n",
      "loss: 1.032168  [ 6464/40000]\n",
      "loss: 1.018626  [12864/40000]\n",
      "loss: 0.974697  [19264/40000]\n",
      "loss: 1.009336  [25664/40000]\n",
      "loss: 0.970123  [32064/40000]\n",
      "loss: 0.979347  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.023828 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.068486  [   64/40000]\n",
      "loss: 1.029449  [ 6464/40000]\n",
      "loss: 1.017802  [12864/40000]\n",
      "loss: 0.973489  [19264/40000]\n",
      "loss: 1.009175  [25664/40000]\n",
      "loss: 0.969156  [32064/40000]\n",
      "loss: 0.978708  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 1.023656 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.067734  [   64/40000]\n",
      "loss: 1.029832  [ 6464/40000]\n",
      "loss: 1.016636  [12864/40000]\n",
      "loss: 0.973183  [19264/40000]\n",
      "loss: 1.008727  [25664/40000]\n",
      "loss: 0.967838  [32064/40000]\n",
      "loss: 0.976127  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.4%, Avg loss: 1.023922 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.067480  [   64/40000]\n",
      "loss: 1.027730  [ 6464/40000]\n",
      "loss: 1.016699  [12864/40000]\n",
      "loss: 0.972444  [19264/40000]\n",
      "loss: 1.008054  [25664/40000]\n",
      "loss: 0.966682  [32064/40000]\n",
      "loss: 0.976127  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.023621 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 1.067459  [   64/40000]\n",
      "loss: 1.025677  [ 6464/40000]\n",
      "loss: 1.017102  [12864/40000]\n",
      "loss: 0.971781  [19264/40000]\n",
      "loss: 1.007777  [25664/40000]\n",
      "loss: 0.966978  [32064/40000]\n",
      "loss: 0.975826  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.023273 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.065394  [   64/40000]\n",
      "loss: 1.025529  [ 6464/40000]\n",
      "loss: 1.014798  [12864/40000]\n",
      "loss: 0.971563  [19264/40000]\n",
      "loss: 1.005869  [25664/40000]\n",
      "loss: 0.967291  [32064/40000]\n",
      "loss: 0.974073  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.023309 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 1.064974  [   64/40000]\n",
      "loss: 1.022967  [ 6464/40000]\n",
      "loss: 1.016371  [12864/40000]\n",
      "loss: 0.970589  [19264/40000]\n",
      "loss: 1.004746  [25664/40000]\n",
      "loss: 0.967276  [32064/40000]\n",
      "loss: 0.972752  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.023328 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 1.063443  [   64/40000]\n",
      "loss: 1.024577  [ 6464/40000]\n",
      "loss: 1.016569  [12864/40000]\n",
      "loss: 0.971447  [19264/40000]\n",
      "loss: 1.005093  [25664/40000]\n",
      "loss: 0.966586  [32064/40000]\n",
      "loss: 0.971450  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.9%, Avg loss: 1.023372 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 1.062546  [   64/40000]\n",
      "loss: 1.021063  [ 6464/40000]\n",
      "loss: 1.018070  [12864/40000]\n",
      "loss: 0.969941  [19264/40000]\n",
      "loss: 1.002473  [25664/40000]\n",
      "loss: 0.967084  [32064/40000]\n",
      "loss: 0.970356  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.023340 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 1.061931  [   64/40000]\n",
      "loss: 1.017511  [ 6464/40000]\n",
      "loss: 1.018429  [12864/40000]\n",
      "loss: 0.967587  [19264/40000]\n",
      "loss: 1.002236  [25664/40000]\n",
      "loss: 0.964386  [32064/40000]\n",
      "loss: 0.970392  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.023507 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.061541  [   64/40000]\n",
      "loss: 1.016108  [ 6464/40000]\n",
      "loss: 1.017766  [12864/40000]\n",
      "loss: 0.966531  [19264/40000]\n",
      "loss: 1.001788  [25664/40000]\n",
      "loss: 0.963545  [32064/40000]\n",
      "loss: 0.968873  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 48.0%, Avg loss: 1.023527 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 1.060919  [   64/40000]\n",
      "loss: 1.016909  [ 6464/40000]\n",
      "loss: 1.016907  [12864/40000]\n",
      "loss: 0.965082  [19264/40000]\n",
      "loss: 0.999030  [25664/40000]\n",
      "loss: 0.962853  [32064/40000]\n",
      "loss: 0.967524  [38464/40000]\n",
      "Test Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.024054 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1 + passed}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "passed = passed + epochs\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a263a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
